{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning using the coursera tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Coding the different fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\" parameter : Z an array\n",
    "        return sigmoid(Z) an array\"\"\"\n",
    "    A=1/(1+np.exp(-Z))\n",
    "    cache=Z\n",
    "    assert(A.shape == Z.shape)\n",
    "    return A,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.26894142, 0.26894142, 0.26894142, 0.26894142, 0.26894142]),\n",
       " array([-1., -1., -1., -1., -1.]))"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.zeros(5)-1\n",
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \"\"\" parameter : Z an array\n",
    "        return sigmoid(Z) an array\"\"\"\n",
    "    A=np.where(Z>=0,Z,0)\n",
    "    cache=Z\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    return A,cache\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0.]), array([-1., -1., -1., -1., -1.]))"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single RELU unit.\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single SIGMOID unit.\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    W1 = np.random.randn(n_h,n_x)*0.01\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y,n_h)*0.01\n",
    "    b2 = np.zeros((n_y,1))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert(W1.shape == (n_h, n_x))\n",
    "    assert(b1.shape == (n_h, 1))\n",
    "    assert(W2.shape == (n_y, n_h))\n",
    "    assert(b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    Z =  np.dot(W,A)+b\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = relu(Z)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function defined by equation (7).\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Compute loss from aL and y.\n",
    "    ### START CODE HERE ### (≈ 1 lines of code)\n",
    "    cost = -1/m*np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    dW = 1/m*np.dot(dZ,A_prev.T)\n",
    "    db = 1/m*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dZ = relu_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ,linear_cache)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dZ = sigmoid_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ,linear_cache)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] += -learning_rate*grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] += -learning_rate*grads[\"db\" + str(l+1)]\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset but with no transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_price = pd.read_csv(\"/Users/serrano/Documents/cours_centrale/projet_inno/git/projets8/scripts_Python/data/historic_price/\"+'BNP'+\".PA.csv\", sep=\",\")\n",
    "X_clf = np.array(historic_price.drop(['Date','Close','Adj close'], axis=1).values)\n",
    "y = np.array(historic_price['Close'].values)\n",
    "X_clf=X_clf[1:,:]\n",
    "y_clf=np.zeros((1,len(y)-1))\n",
    "for i in range(len(y)-1):\n",
    "    if y[i]>=y[i+1]:\n",
    "        y_clf[0,i]=1\n",
    "        \n",
    "y_clf=np.array(y_clf)\n",
    "X_clf=X_clf.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1277)\n",
      "(1, 1277)\n"
     ]
    }
   ],
   "source": [
    "np.squeeze(y_clf)\n",
    "print(X_clf.shape)\n",
    "print(y_clf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x = 4     \n",
    "n_h = 3\n",
    "n_y = 1\n",
    "layers_dims = (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_2(X,Y,parameters):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    Z,cache1=linear_activation_forward(X, W1, b1, \"relu\")\n",
    "    A,cache2=linear_activation_forward(Z, W2, b2, \"sigmoid\")\n",
    "    A=np.where(A>=0.5,1,0)\n",
    "    \n",
    "    return 1-np.mean(abs(Y-A))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Implements a two-layer neural network: LINEAR->RELU->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (n_x, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- dimensions of the layers (n_x, n_h, n_y)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- If set to True, this will print the cost every 100 iterations \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary containing W1, W2, b1, and b2\n",
    "    \"\"\"\n",
    "    \n",
    "    grads = {}\n",
    "    costs = []                              # to keep track of the cost\n",
    "    m = X.shape[1]                           # number of examples\n",
    "    (n_x, n_h, n_y) = layers_dims\n",
    "    \n",
    "    # Initialize parameters dictionary, by calling one of the functions you'd previously implemented\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Get W1, b1, W2 and b2 from the dictionary parameters.\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: LINEAR -> RELU -> LINEAR -> SIGMOID. Inputs: \"X, W1, b1, W2, b2\". Output: \"A1, cache1, A2, cache2\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        A1, cache1 = linear_activation_forward(X, W1, b1, \"relu\")\n",
    "        A2, cache2 = linear_activation_forward(A1, W2, b2, \"sigmoid\")\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Compute cost\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        cost = compute_cost(A2, Y)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Initializing backward propagation\n",
    "        dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2))\n",
    "        \n",
    "        # Backward propagation. Inputs: \"dA2, cache2, cache1\". Outputs: \"dA1, dW2, db2; also dA0 (not used), dW1, db1\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dA1, dW2, db2 = linear_activation_backward(dA2, cache2, \"sigmoid\")\n",
    "        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, \"relu\")\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Set grads['dWl'] to dW1, grads['db1'] to db1, grads['dW2'] to dW2, grads['db2'] to db2\n",
    "        grads['dW1'] = dW1\n",
    "        grads['db1'] = db1\n",
    "        grads['dW2'] = dW2\n",
    "        grads['db2'] = db2\n",
    "        \n",
    "        # Update parameters.\n",
    "        ### START CODE HERE ### (approx. 1 line of code)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Retrieve W1, b1, W2, b2 from parameters\n",
    "        W1 = parameters[\"W1\"]\n",
    "        b1 = parameters[\"b1\"]\n",
    "        W2 = parameters[\"W2\"]\n",
    "        b2 = parameters[\"b2\"]\n",
    "        \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "       \n",
    "    # plot the cost\n",
    "\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "Xtr, Xte, ytr, yte = model_selection.train_test_split(X_clf.T, y_clf.T, \n",
    "                                                      test_size=0.3)\n",
    "\n",
    "Xtr = preprocessing.scale(Xtr)\n",
    "\n",
    "Xtr, Xte, ytr, yte =Xtr.T, Xte.T, ytr.T, yte.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 893)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6931478143212833\n",
      "Cost after iteration 100: 0.6914305285529037\n",
      "Cost after iteration 200: 0.6894886578660798\n",
      "Cost after iteration 300: 0.6892041458037835\n",
      "Cost after iteration 400: 0.6890971532072452\n",
      "Cost after iteration 500: 0.6890717798196817\n",
      "Cost after iteration 600: 0.6890539894749947\n",
      "Cost after iteration 700: 0.689034369943563\n",
      "Cost after iteration 800: 0.689017386924149\n",
      "Cost after iteration 900: 0.6889992106190254\n",
      "Cost after iteration 1000: 0.6889793751394346\n",
      "Cost after iteration 1100: 0.6889581632649592\n",
      "Cost after iteration 1200: 0.688936140021534\n",
      "Cost after iteration 1300: 0.6889121634154992\n",
      "Cost after iteration 1400: 0.6888817081641244\n",
      "Cost after iteration 1500: 0.6888485420787501\n",
      "Cost after iteration 1600: 0.6888150704391541\n",
      "Cost after iteration 1700: 0.6887777129631099\n",
      "Cost after iteration 1800: 0.6887308861356488\n",
      "Cost after iteration 1900: 0.6886663388142185\n",
      "Cost after iteration 2000: 0.6885991644303454\n",
      "Cost after iteration 2100: 0.6885293248485362\n",
      "Cost after iteration 2200: 0.6884606682391736\n",
      "Cost after iteration 2300: 0.6883807874284306\n",
      "Cost after iteration 2400: 0.6882864114467163\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a12ca2b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = two_layer_model(Xtr, ytr,learning_rate = 1 ,layers_dims = (n_x, n_h, n_y), num_iterations = 2500, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5520716685330347\n"
     ]
    }
   ],
   "source": [
    "predictions_train = predict_2(Xtr, ytr, parameters)\n",
    "print(predictions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L-Layer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() (there are L-1 of them, indexed from 0 to L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], \"relu\")\n",
    "        caches.append(cache)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    ### END CODE HERE ###\n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
    "    \n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"dAL, current_cache\". Outputs: \"grads[\"dAL-1\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Loop from l=L-2 to l=0\n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        # Inputs: \"grads[\"dA\" + str(l + 1)], current_cache\". Outputs: \"grads[\"dA\" + str(l)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n",
    "        ### START CODE HERE ### (approx. 5 lines)\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l+1)], current_cache, \"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    costs = []                         # keep track of cost\n",
    "    \n",
    "    # Parameters initialization. (≈ 1 line of code)\n",
    "    ### START CODE HERE ###\n",
    "    parameters = initialize_parameters_deep(layer_dims)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Compute cost.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        cost = compute_cost(AL,Y)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "        # Backward propagation.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        ### END CODE HERE ###\n",
    " \n",
    "        # Update parameters.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        ### END CODE HERE ###\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "Xtr, Xte, ytr, yte = model_selection.train_test_split(X_clf.T, y_clf.T, \n",
    "                                                      test_size=0.3)\n",
    "\n",
    "Xtr = preprocessing.scale(Xtr)\n",
    "\n",
    "Xtr, Xte, ytr, yte =Xtr.T, Xte.T, ytr.T, yte.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_L(X,Y,parameters):\n",
    "    A,caches=L_model_forward(X, parameters)\n",
    "    A=np.where(A>=0.5,1,0)\n",
    "    \n",
    "    return 1-np.mean(abs(Y-A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dims=[4,5,6,4,3,5,4,5,6,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 0.692102\n",
      "Cost after iteration 200: 0.691383\n",
      "Cost after iteration 300: 0.690889\n",
      "Cost after iteration 400: 0.690550\n",
      "Cost after iteration 500: 0.690317\n",
      "Cost after iteration 600: 0.690156\n",
      "Cost after iteration 700: 0.690046\n",
      "Cost after iteration 800: 0.689970\n",
      "Cost after iteration 900: 0.689918\n",
      "Cost after iteration 1000: 0.689882\n",
      "Cost after iteration 1100: 0.689857\n",
      "Cost after iteration 1200: 0.689840\n",
      "Cost after iteration 1300: 0.689828\n",
      "Cost after iteration 1400: 0.689820\n",
      "Cost after iteration 1500: 0.689814\n",
      "Cost after iteration 1600: 0.689811\n",
      "Cost after iteration 1700: 0.689808\n",
      "Cost after iteration 1800: 0.689806\n",
      "Cost after iteration 1900: 0.689805\n",
      "Cost after iteration 2000: 0.689804\n",
      "Cost after iteration 2100: 0.689803\n",
      "Cost after iteration 2200: 0.689803\n",
      "Cost after iteration 2300: 0.689803\n",
      "Cost after iteration 2400: 0.689803\n",
      "Cost after iteration 2500: 0.689802\n",
      "Cost after iteration 2600: 0.689802\n",
      "Cost after iteration 2700: 0.689802\n",
      "Cost after iteration 2800: 0.689802\n",
      "Cost after iteration 2900: 0.689802\n",
      "Cost after iteration 3000: 0.689802\n",
      "Cost after iteration 3100: 0.689802\n",
      "Cost after iteration 3200: 0.689802\n",
      "Cost after iteration 3300: 0.689802\n",
      "Cost after iteration 3400: 0.689802\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a8a5d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(Xtr, ytr,layers_dims,learning_rate=0.0075, num_iterations = 3500, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5408734602463605"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_L(Xtr,ytr,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46354166666666663"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xte=preprocessing.scale(Xte)\n",
    "predict_L(Xte,yte,parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a matrix of depth k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "stock = \"BNP.PA\"#\n",
    "#################\n",
    "from datetime import datetime\n",
    "\n",
    "dataFrame = pd.read_csv(\"/Users/serrano/Documents/cours_centrale/projet_inno/git/projets8/script_macro/\"+stock+\".csv\", sep=\",\")\n",
    "# les valeurs les plus recentes en haut\n",
    "data = np.array(dataFrame.values)[::-1]\n",
    "initialData = np.array(dataFrame.values)[::-1]\n",
    "\n",
    "initialHeader= list(dataFrame)\n",
    "header = list(dataFrame)\n",
    "\n",
    "\n",
    "# ici data ne comporte que les donnees series de prix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inflation\n",
    "inflation = pd.read_excel(\"/Users/serrano/Documents/cours_centrale/projet_inno/git/projets8/script_macro/\"+\"Inflation.xlsx\")\n",
    "temp = np.array(inflation.values)\n",
    "\n",
    "inflation_values = []\n",
    "for i in range(len(temp)):\n",
    "    if len(str(int(temp[i][1]))) < 2:\n",
    "        date = datetime.strptime(str(int(temp[i][0]))+\"-0\"+str(int(temp[i][1])), '%Y-%m')\n",
    "    else:\n",
    "        date = datetime.strptime(str(int(temp[i][0]))+\"-\"+str(int(temp[i][1])), '%Y-%m')\n",
    "    value = float(int(1000*temp[i][2]))/1000\n",
    "    inflation_values.append([date,value])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consumer sentiment\n",
    "consumer_sentiment = pd.read_excel(\"/Users/serrano/Documents/cours_centrale/projet_inno/git/projets8/script_macro/\"+\"the index of the consumer sentiment.xlsx\")\n",
    "temp = np.array(consumer_sentiment.values)\n",
    "\n",
    "consumer_sentiment_values = []\n",
    "for i in range(len(temp)):\n",
    "    if len(str(int(temp[i][1]))) < 2:\n",
    "        date = datetime.strptime(str(int(temp[i][0]))+\"-0\"+str(int(temp[i][1])), '%m-%Y')\n",
    "    else:\n",
    "        date = datetime.strptime(str(int(temp[i][0]))+\"-\"+str(int(temp[i][1])), '%m-%Y')\n",
    "    value = float(int(1000*temp[i][2]))/1000\n",
    "    consumer_sentiment_values.append([date,value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interest rates fed\n",
    "interest_rates = pd.read_excel(\"/Users/serrano/Documents/cours_centrale/projet_inno/git/projets8/script_macro/\"+\"interest rates fed.xlsx\")\n",
    "interest_values = np.array(interest_rates.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euro-dollar rate\n",
    "euro_dollar = pd.read_excel(\"/Users/serrano/Documents/cours_centrale/projet_inno/git/projets8/script_macro/\"+\"EUR_DOLL.xlsx\")\n",
    "euro_dollar_values = np.array(euro_dollar.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_data(data,list_usedData,parameter_values,name_parameter):\n",
    "    data_temp = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        vector = []\n",
    "        for k in range(len(data[i])):\n",
    "            vector.append(data[i][k])\n",
    "        date = datetime.strptime(data[i][0], '%Y-%m-%d')\n",
    "        if date < parameter_values[0][0]:\n",
    "            vector.append(parameter_values[0][1])\n",
    "        else:\n",
    "            index = 0\n",
    "            while date > parameter_values[index][0] and index < len(parameter_values)-1:\n",
    "                index += 1\n",
    "            if index < len(parameter_values)-1:\n",
    "                vector.append(parameter_values[index][1])\n",
    "                # approximation en escalier\n",
    "            else:\n",
    "                vector.append(parameter_values[-1][1])\n",
    "        data_temp.append(vector)   \n",
    "        \n",
    "    list_usedData.append(name_parameter)\n",
    "    return data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_to_data(data,header,inflation_values, \"Inflation\")\n",
    "data = add_to_data(data,header,consumer_sentiment_values, \"Consumer sentiment\")\n",
    "data = add_to_data(data,header,interest_values, \"Interest rates fed\")\n",
    "data = add_to_data(data,header,euro_dollar_values,\"euro-dollar\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Open',\n",
       " 'High',\n",
       " 'Low',\n",
       " 'Close',\n",
       " 'Adj Close',\n",
       " 'Volume',\n",
       " 'Inflation',\n",
       " 'Consumer sentiment',\n",
       " 'Interest rates fed',\n",
       " 'euro-dollar']"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_matrix(matrix,k):\n",
    "    \"\"\" k : integer \"\"\"\n",
    "    p=matrix.shape[1]\n",
    "    n=matrix.shape[0]\n",
    "    data_matrix=np.zeros((n-k,p*k))\n",
    "    for i in range(k):\n",
    "        for j in range(n-k):\n",
    "            data_matrix[j,i*p:(i+1)*p]=matrix[j+i,:]\n",
    "    return data_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63.740002 64.279999 63.130001 ... 95.7       1.41      1.2263  ]\n",
      " [64.07     64.660004 62.25     ... 95.7       1.41      1.2273  ]\n",
      " [64.589996 65.709999 63.939999 ... 95.7       1.41      1.2252  ]\n",
      " ...\n",
      " [46.560001 47.215    46.005001 ... 78.6       0.14      1.3325  ]\n",
      " [46.299999 47.5      46.200001 ... 78.6       0.14      1.3327  ]\n",
      " [46.029999 46.119999 45.279999 ... 78.6       0.14      1.348   ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1278, 8)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=pd.DataFrame(data,columns=header)\n",
    "data = np.array(dataframe.drop(['Date','Close','Adj Close'], axis=1).values)\n",
    "print(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1276, 8)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=1\n",
    "new_data=create_data_matrix(data,k)\n",
    "new_data=new_data[1:,:]\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 1)\n",
      "(1276, 1)\n"
     ]
    }
   ],
   "source": [
    "y=np.array(dataframe['Close'].values)\n",
    "new_y=np.zeros((len(y)-(k+1),1))\n",
    "for i in range(len(y)-(k+1)):\n",
    "    if y[i]>y[i+1]:  \n",
    "        new_y[i,0]=1\n",
    "new_y=np.array(new_y)\n",
    "print(new_y.shape)\n",
    "np.squeeze(new_y)\n",
    "print(new_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dims=[8,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "Xtr, Xte, ytr, yte = model_selection.train_test_split(new_data, new_y, \n",
    "                                                      test_size=0.3)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(Xtr)  \n",
    "Xtr = scaler.transform(Xtr)  \n",
    "# apply same transformation to test data\n",
    "Xte= scaler.transform(Xte)\n",
    "\n",
    "Xtr, Xte, ytr, yte =Xtr.T, Xte.T, ytr.T, yte.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.692702\n",
      "Cost after iteration 100: 0.692381\n",
      "Cost after iteration 200: 0.692117\n",
      "Cost after iteration 300: 0.691897\n",
      "Cost after iteration 400: 0.691714\n",
      "Cost after iteration 500: 0.691560\n",
      "Cost after iteration 600: 0.691429\n",
      "Cost after iteration 700: 0.691318\n",
      "Cost after iteration 800: 0.691223\n",
      "Cost after iteration 900: 0.691140\n",
      "Cost after iteration 1000: 0.691068\n",
      "Cost after iteration 1100: 0.691005\n",
      "Cost after iteration 1200: 0.690949\n",
      "Cost after iteration 1300: 0.690899\n",
      "Cost after iteration 1400: 0.690854\n",
      "Cost after iteration 1500: 0.690814\n",
      "Cost after iteration 1600: 0.690777\n",
      "Cost after iteration 1700: 0.690744\n",
      "Cost after iteration 1800: 0.690713\n",
      "Cost after iteration 1900: 0.690685\n",
      "Cost after iteration 2000: 0.690659\n",
      "Cost after iteration 2100: 0.690635\n",
      "Cost after iteration 2200: 0.690612\n",
      "Cost after iteration 2300: 0.690591\n",
      "Cost after iteration 2400: 0.690572\n",
      "Cost after iteration 2500: 0.690554\n",
      "Cost after iteration 2600: 0.690536\n",
      "Cost after iteration 2700: 0.690520\n",
      "Cost after iteration 2800: 0.690505\n",
      "Cost after iteration 2900: 0.690491\n",
      "Cost after iteration 3000: 0.690477\n",
      "Cost after iteration 3100: 0.690464\n",
      "Cost after iteration 3200: 0.690452\n",
      "Cost after iteration 3300: 0.690441\n",
      "Cost after iteration 3400: 0.690430\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a12ca04e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(Xtr, ytr,layers_dims,learning_rate=0.001, num_iterations = 3500, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the built-up fonctions from sklearn : MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yte : (383,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "alpha=10.0 ** -np.arange(1, 7)\n",
    "param_grid = {'alpha': alpha}\n",
    "\n",
    "ytr = ytr.reshape((-1,)) \n",
    "yte = yte.reshape((-1,))\n",
    "print(\"yte : \"+str(yte.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='adam',activation=\"relu\", alpha=0, learning_rate=\"constant\",\n",
    "...                     hidden_layer_sizes=(100,50,30,20),max_iter=5000,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 50, 30, 20), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=5000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(Xtr.T,ytr.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.517\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred=clf.predict(Xte.T)\n",
    "print(\"Accuracy: %.3f\" % metrics.accuracy_score(yte.T, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import model_selection\n",
    "alpha=10.0 ** -np.arange(1, 7)\n",
    "param_grid = {'alpha': alpha}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/serrano/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 2),\n",
       "       learning_rate='invscaling', learning_rate_init...le=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1= MLPClassifier(solver='adam', learning_rate=\"invscaling\",\n",
    "...                     hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100,100,100,100,100,2),max_iter=3500,random_state=1)\n",
    "clf_opt=model_selection.GridSearchCV(clf_1,param_grid,cv=3)\n",
    "clf_opt.fit(Xtr.T,ytr.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 2),\n",
      "       learning_rate='invscaling', learning_rate_init=0.001, max_iter=3500,\n",
      "       momentum=0.9, nesterovs_momentum=True, power_t=0.5, random_state=1,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(clf_opt.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=clf_opt.best_estimator_.predict(Xte.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.517\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.3f\" % metrics.accuracy_score(yte.T, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation des cours des prix en rapport "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_price = pd.read_csv(\"/Users/serrano/Documents/cours_centrale/projet_inno/git/projets8/scripts_Python/data/historic_price/\"+'BNP'+\".PA.csv\", sep=\",\")\n",
    "X_clf = np.array(historic_price.drop(['Date','Adj close'], axis=1).values)\n",
    "y = np.array(historic_price['Close'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zero_one(y):\n",
    "    y=np.array(y)\n",
    "    n=y.shape[0]\n",
    "    y_clf=np.zeros(n-2)\n",
    "    for i in range(n-2):\n",
    "        if y[i]>=y[i+1]:\n",
    "            y_clf[i]=1\n",
    "    return y_clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_zero_one([2,3,2,4,5,2,5,3,4,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ratio_matrix(matrix):\n",
    "    \"\"\" k : integer \"\"\"\n",
    "    p=matrix.shape[1]\n",
    "    n=matrix.shape[0]\n",
    "    data_matrix=np.zeros((n-1,p))\n",
    "    for i in range(n-1):\n",
    "        data_matrix[i,:]=matrix[i,:]/matrix[i+1,:] #Xi -> jour i et Xi+1 -> jour i-1\n",
    "        \n",
    "    data_matrix=data_matrix[1:n-1,:]\n",
    "    return data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 5)\n",
      "(1276,)\n"
     ]
    }
   ],
   "source": [
    "data_ratio=np.log(create_ratio_matrix(X_clf))\n",
    "y_clf=create_zero_one(y)\n",
    "print(data_ratio.shape)\n",
    "print(y_clf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='adam',activation=\"relu\", alpha=0.01, learning_rate=\"constant\",\n",
    "...                     hidden_layer_sizes=(100,90,80,70,50,40,30,20,10),max_iter=5000,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "Xtr, Xte, ytr, yte = model_selection.train_test_split(data_ratio, y_clf, \n",
    "                                                      test_size=0.3)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(Xtr)  \n",
    "Xtr = scaler.transform(Xtr)  \n",
    "# apply same transformation to test data\n",
    "Xte= scaler.transform(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 90, 80, 70, 50, 40, 30, 20, 10),\n",
       "       learning_rate='constant', learning_rate_init=0.001, max_iter=5000,\n",
       "       momentum=0.9, nesterovs_momentum=True, power_t=0.5, random_state=1,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(Xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.760\n"
     ]
    }
   ],
   "source": [
    "#test on the training set to see if it fits well the data -> estimation of the biais\n",
    "from sklearn import metrics\n",
    "y_pred=clf.predict(Xtr)\n",
    "print(\"Accuracy: %.3f\" % metrics.accuracy_score(ytr, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.486\n"
     ]
    }
   ],
   "source": [
    "#test on the test set to see if it predicts well the data -> estimation of the variance\n",
    "y_pred=clf.predict(Xte)\n",
    "print(\"Accuracy: %.3f\" % metrics.accuracy_score(yte, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.train_test_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On essaye d'ajouter de la profondeur k\n",
    "k=13\n",
    "data_k=create_data_matrix(data_ratio,k)\n",
    "y_clf_k=y_clf[:len(y_clf)-k]\n",
    "\n",
    "Xtr, Xte, ytr, yte = model_selection.train_test_split(data_k, y_clf_k, \n",
    "                                                      test_size=0.3)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(Xtr)  \n",
    "Xtr = scaler.transform(Xtr)  \n",
    "# apply same transformation to test data\n",
    "Xte= scaler.transform(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='adam',activation=\"relu\", alpha=0.1, learning_rate=\"constant\",\n",
    "...                     hidden_layer_sizes=(110,100,90,80,70,50,40,30,20,10),max_iter=5000,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(110, 100, 90, 80, 70, 50, 40, 30, 20, 10),\n",
       "       learning_rate='constant', learning_rate_init=0.001, max_iter=5000,\n",
       "       momentum=0.9, nesterovs_momentum=True, power_t=0.5, random_state=10,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(Xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.966\n"
     ]
    }
   ],
   "source": [
    "#test on the training set to see if it fits well the data -> estimation of the biais\n",
    "from sklearn import metrics\n",
    "y_pred=clf.predict(Xtr)\n",
    "print(\"Accuracy: %.3f\" % metrics.accuracy_score(ytr, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.517\n"
     ]
    }
   ],
   "source": [
    "#test on the test set to see if it predicts well the data -> estimation of the variance\n",
    "y_pred=clf.predict(Xte)\n",
    "print(\"Accuracy: %.3f\" % metrics.accuracy_score(yte, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709841628959277\n",
      "0.5143799472295515\n"
     ]
    }
   ],
   "source": [
    "###accuracy on training and testing sets n times to obtain an empirical mean\n",
    "n=20\n",
    "m_test=0\n",
    "m_train=0\n",
    "for i in range(n):\n",
    "    clf=MLPClassifier(solver='adam',activation=\"relu\", alpha=0.1, learning_rate=\"constant\",hidden_layer_sizes=(110,100,90,80,70,50,40,30,20,10),max_iter=5000, random_state=i)\n",
    "    Xtr, Xte, ytr, yte = model_selection.train_test_split(data_k, y_clf_k, \n",
    "                                                      test_size=0.3)\n",
    "    \n",
    "    scaler = StandardScaler()  \n",
    "    # Don't cheat - fit only on training data\n",
    "    scaler.fit(Xtr)  \n",
    "    Xtr = scaler.transform(Xtr)  \n",
    "    # apply same transformation to test data\n",
    "    Xte= scaler.transform(Xte)\n",
    "    \n",
    "    clf.fit(Xtr,ytr)\n",
    "    y_pred_train=clf.predict(Xtr)\n",
    "    m_train+=metrics.accuracy_score(ytr, y_pred_train)\n",
    "    \n",
    "    y_pred_test=clf.predict(Xte)\n",
    "    m_test+=metrics.accuracy_score(yte, y_pred_test)\n",
    "    \n",
    "print( m_train/n)\n",
    "print(m_test/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [5,10,15,20,25,30,35,40,45]:\n",
    "    data_k=create_data_matrix(data_ratio,k)\n",
    "    y_clf_k=y_clf[:len(y_clf)-k]\n",
    "\n",
    "    n=20\n",
    "    m_test=0\n",
    "    m_train=0\n",
    "    for i in range(n):\n",
    "        clf=MLPClassifier(solver='adam',activation=\"relu\", alpha=0.1, learning_rate=\"constant\",hidden_layer_sizes=(110,100,90,80,70,50,40,30,20,10),max_iter=5000, random_state=i)\n",
    "        Xtr, Xte, ytr, yte = model_selection.train_test_split(data_k, y_clf_k, \n",
    "                                                      test_size=0.3)\n",
    "    \n",
    "        scaler = StandardScaler()  \n",
    "        # Don't cheat - fit only on training data\n",
    "        scaler.fit(Xtr)  \n",
    "        Xtr = scaler.transform(Xtr)  \n",
    "        # apply same transformation to test data\n",
    "        Xte= scaler.transform(Xte)\n",
    "\n",
    "        clf.fit(Xtr,ytr)\n",
    "        y_pred_train=clf.predict(Xtr)\n",
    "        m_train+=metrics.accuracy_score(ytr, y_pred_train)\n",
    "\n",
    "        y_pred_test=clf.predict(Xte)\n",
    "        m_test+=metrics.accuracy_score(yte, y_pred_test)\n",
    "    print(k+\":\")\n",
    "    print( m_train/n)\n",
    "    print(m_test/n)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying deep Learning with all the stocks to predict only one (not finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_names=[\"AC\",\"ACA\",\"AI\",\"AIR\",\"ATO\",\"BN\",\"BNP\",\"CA\",\"CAP\",\"DG\",\"EI\",\"EN\",\"ENGI\",\"FP\",\"FR\",\"GLE\",\"KER\",\"LHN\",\"LR\",\"MC\",\"ML\",\"OR\",\"ORA\",\"SAN\",\"SGO\",\"SU\",\"SW\",\"UG\",\"VIE\",\"VIV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stock_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-c91c23c6d096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_clf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mstock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstock_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mhistoric_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/serrano/Documents/cours_centrale/projet_inno/git/projets8/scripts_Python/data/historic_price/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstock\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".PA.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistoric_price\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Adj close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stock_names' is not defined"
     ]
    }
   ],
   "source": [
    "X_clf= []\n",
    "y_list=[]\n",
    "for stock in stock_names:\n",
    "    historic_price = pd.read_csv(\"/Users/serrano/Documents/cours_centrale/projet_inno/git/projets8/scripts_Python/data/historic_price/\"+stock+\".PA.csv\", sep=\",\")\n",
    "    X_clf.append(np.array(historic_price.drop(['Date','Close','Adj close'], axis=1).values))\n",
    "    y_list.append(np.array(historic_price['Close'].values))\n",
    "##Transformation en rapport\n",
    "for i in range(len(X_clf)):\n",
    "    X_clf[i]=create_ratio_matrix(X_clf[i])\n",
    "    y_list[i]=create_zero_one(y_list[i])\n",
    "X_clf=np.array(X_clf)\n",
    "print(y_list[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-757091b6900b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_clf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(X_clf.shape[0])\n",
    "for i in range(X_clf.shape[0]):\n",
    "    print(X_clf[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-f815035dbdcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "data_matrix=np.concatenate(X_clf, axis=1) \n",
    "print(data_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
